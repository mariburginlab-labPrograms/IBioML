#!/usr/bin/env python3
"""
Ejemplos de uso de par√°metros de capas exclusivas en model_space.

Este script muestra c√≥mo configurar num_exclusive_layers y exclusive_hidden_size
tanto con valores fijos como con rangos de b√∫squeda (optimizables).

NOTA: Este es un script de documentaci√≥n. Los model_space aqu√≠ son ejemplos
      de c√≥mo estructurar tu configuraci√≥n, no se ejecutan modelos reales.
"""

# ========================================
# PARTE 1: Configuraciones fijas
# ========================================

print("\n" + "="*80)
print("PARTE 1: CONFIGURACIONES FIJAS en model_space")
print("="*80)

# Ejemplo 1: Sin capas exclusivas (comportamiento cl√°sico)
model_space_1 = {
    "model_class": "DualOutputMLPModel",  # O usar la clase directamente
    "output_size": 1,
    "hidden_size": 128,
    "num_layers": 3,
    "dropout": 0.2,
    "lr": 0.001,
    "batch_size": 64,
    "num_epochs": 10,
    "es_patience": 3,
    "reg_type": None,
    "lambda_reg": 1e-4,
    "device": "cpu",
    
    # Par√°metros de capas exclusivas
    "num_exclusive_layers": 0,  # 0 = sin capas exclusivas
}

print("\nüìù Ejemplo 1: Sin capas exclusivas")
print("   num_exclusive_layers: 0")
print("   ‚Üí Se traduce a use_exclusive=False")

# Ejemplo 2: Con 1 capa exclusiva del mismo tama√±o (default mejorado)
model_space_2 = {
    "model_class": "DualOutputMLPModel",
    "output_size": 1,
    "hidden_size": 128,
    "num_layers": 3,
    "dropout": 0.2,
    "lr": 0.001,
    "batch_size": 64,
    "num_epochs": 10,
    "es_patience": 3,
    "reg_type": None,
    "lambda_reg": 1e-4,
    "device": "cpu",
    
    # Par√°metros de capas exclusivas
    "num_exclusive_layers": 1,  # 1 capa exclusiva
    # exclusive_hidden_size no especificado = usa hidden_size (128)
}

print("\nüìù Ejemplo 2: Con 1 capa exclusiva del mismo tama√±o")
print("   num_exclusive_layers: 1")
print("   exclusive_hidden_size: (no especificado, usa hidden_size=128)")

# Ejemplo 3: Con capas exclusivas m√°s peque√±as
model_space_3 = {
    "model_class": "DualOutputMLPModel",
    "output_size": 1,
    "hidden_size": 128,
    "num_layers": 3,
    "dropout": 0.2,
    "lr": 0.001,
    "batch_size": 64,
    "num_epochs": 10,
    "es_patience": 3,
    "reg_type": None,
    "lambda_reg": 1e-4,
    "device": "cpu",
    
    # Par√°metros de capas exclusivas
    "num_exclusive_layers": 1,
    "exclusive_hidden_size": 64,  # M√°s peque√±o que hidden_size
}

print("\nüìù Ejemplo 3: Con capas exclusivas m√°s peque√±as")
print("   num_exclusive_layers: 1")
print("   exclusive_hidden_size: 64 (< hidden_size=128)")
print("   ‚Üí Menos par√°metros, m√°s r√°pido")

# Ejemplo 4: Con m√∫ltiples capas exclusivas
model_space_4 = {
    "model_class": "DualOutputMLPModel",
    "output_size": 1,
    "hidden_size": 128,
    "num_layers": 3,
    "dropout": 0.2,
    "lr": 0.001,
    "batch_size": 64,
    "num_epochs": 10,
    "es_patience": 3,
    "reg_type": None,
    "lambda_reg": 1e-4,
    "device": "cpu",
    
    # Par√°metros de capas exclusivas
    "num_exclusive_layers": 3,  # 3 capas exclusivas por output
    "exclusive_hidden_size": 96,
}

print("\nüìù Ejemplo 4: Con m√∫ltiples capas exclusivas")
print("   num_exclusive_layers: 3")
print("   exclusive_hidden_size: 96")
print("   ‚Üí Redes m√°s profundas en las ramas exclusivas")

# ========================================
# PARTE 2: Configuraciones optimizables (b√∫squeda de hiperpar√°metros)
# ========================================

print("\n\n" + "="*80)
print("PARTE 2: CONFIGURACIONES OPTIMIZABLES (b√∫squeda con Optuna)")
print("="*80)

# Ejemplo 5: Optimizar si usar capas exclusivas o no
model_space_5 = {
    "model_class": "DualOutputMLPModel",
    "output_size": 1,
    "hidden_size": 128,
    "num_layers": 3,
    "dropout": 0.2,
    "lr": (float, 1e-4, 1e-2, True),  # Optimizable (log scale)
    "batch_size": 64,
    "num_epochs": 10,
    "es_patience": 3,
    "reg_type": None,
    "lambda_reg": 1e-4,
    "device": "cpu",
    
    # Par√°metros de capas exclusivas optimizables
    "num_exclusive_layers": (int, 0, 2),  # Buscar entre 0, 1, 2 capas
}

print("\nüìù Ejemplo 5: Optimizar n√∫mero de capas exclusivas")
print("   num_exclusive_layers: (int, 0, 2)")
print("   ‚Üí Optuna probar√° 0 (sin exclusive), 1 o 2 capas")

# Ejemplo 6: Optimizar tama√±o de capas exclusivas
model_space_6 = {
    "model_class": "DualOutputMLPModel",
    "output_size": 1,
    "hidden_size": (int, 64, 256, 64),  # Buscar: 64, 128, 192, 256
    "num_layers": 3,
    "dropout": 0.2,
    "lr": (float, 1e-4, 1e-2, True),
    "batch_size": 64,
    "num_epochs": 10,
    "es_patience": 3,
    "reg_type": None,
    "lambda_reg": 1e-4,
    "device": "cpu",
    
    # Par√°metros de capas exclusivas optimizables
    "num_exclusive_layers": 1,  # Fijo en 1
    "exclusive_hidden_size": (int, 32, 128, 32),  # Buscar: 32, 64, 96, 128
}

print("\nüìù Ejemplo 6: Optimizar tama√±o de capas exclusivas")
print("   num_exclusive_layers: 1 (fijo)")
print("   exclusive_hidden_size: (int, 32, 128, 32)")
print("   ‚Üí Optuna probar√° tama√±os 32, 64, 96, 128")

# Ejemplo 7: Optimizar ambos par√°metros simult√°neamente
model_space_7 = {
    "model_class": "DualOutputMLPModel",
    "output_size": 1,
    "hidden_size": (int, 128, 256, 64),
    "num_layers": (int, 2, 4),
    "dropout": (float, 0.0, 0.5),
    "lr": (float, 1e-4, 1e-2, True),
    "batch_size": 64,
    "num_epochs": 10,
    "es_patience": 3,
    "reg_type": None,
    "lambda_reg": 1e-4,
    "device": "cpu",
    
    # Ambos par√°metros optimizables
    "num_exclusive_layers": (int, 0, 3),  # 0 a 3 capas
    "exclusive_hidden_size": (int, 64, 256, 64),  # 64 a 256 en pasos de 64
}

print("\nüìù Ejemplo 7: Optimizar ambos par√°metros")
print("   num_exclusive_layers: (int, 0, 3)")
print("   exclusive_hidden_size: (int, 64, 256, 64)")
print("   ‚Üí Optuna explorar√° todas las combinaciones posibles")

# ========================================
# PARTE 3: Casos especiales y consideraciones
# ========================================

print("\n\n" + "="*80)
print("PARTE 3: CASOS ESPECIALES Y CONSIDERACIONES")
print("="*80)

print("\nüí° Consideraciones importantes:")
print()
print("1. num_exclusive_layers = 0:")
print("   ‚Ä¢ Desactiva completamente las capas exclusivas")
print("   ‚Ä¢ Se traduce internamente a use_exclusive=False")
print("   ‚Ä¢ El modelo es m√°s ligero (menos par√°metros)")
print()
print("2. exclusive_hidden_size no especificado:")
print("   ‚Ä¢ Por defecto usa el mismo valor que hidden_size")
print("   ‚Ä¢ √ötil cuando quer√©s mantener la misma capacidad")
print()
print("3. num_exclusive_layers > 1:")
print("   ‚Ä¢ Crea redes m√°s profundas en las ramas exclusivas")
print("   ‚Ä¢ Aumenta la capacidad de especializaci√≥n")
print("   ‚Ä¢ Aumenta el n√∫mero total de par√°metros")
print()
print("4. Trade-offs:")
print("   ‚Ä¢ M√°s capas exclusivas = m√°s especializaci√≥n pero m√°s par√°metros")
print("   ‚Ä¢ Capas m√°s peque√±as = menos par√°metros pero menos capacidad")
print("   ‚Ä¢ Sin exclusive (0) = m√°s r√°pido pero menos especializaci√≥n")

# ========================================
# PARTE 4: Uso con run_study
# ========================================

print("\n\n" + "="*80)
print("PARTE 4: EJEMPLO COMPLETO CON run_study")
print("="*80)

print("""
from ibioml.tuner import run_study
import numpy as np

# Datos sint√©ticos de ejemplo
X = np.random.randn(1000, 50)
y = np.random.randn(1000, 2)  # 2 columnas: posici√≥n y velocidad
T = np.repeat(np.arange(10), 100)  # 10 trials de 100 muestras cada uno

# Configuraci√≥n del model_space con par√°metros de capas exclusivas
model_space = {
    "model_class": "DualOutputMLPModel",
    "output_size": 1,
    "device": "cpu",
    "num_epochs": 50,
    "es_patience": 5,
    "reg_type": None,
    "lambda_reg": 1e-4,
    "batch_size": 64,
    
    # Hiperpar√°metros a optimizar
    "hidden_size": (int, 64, 256, 64),      # 64, 128, 192, 256
    "num_layers": (int, 2, 4),              # 2, 3, 4
    "dropout": (float, 0.0, 0.5),           # 0.0 a 0.5
    "lr": (float, 1e-4, 1e-2, True),        # 0.0001 a 0.01 (log scale)
    
    # Par√°metros de capas exclusivas (optimizables)
    "num_exclusive_layers": (int, 0, 3),    # 0 (sin), 1, 2, 3 capas
    "exclusive_hidden_size": (int, 64, 192, 64),  # 64, 128, 192
}

# Ejecutar b√∫squeda
results = run_study(
    X, y, T,
    model_space=model_space,
    num_trials=20,          # 20 trials de Optuna por fold
    outer_folds=5,          # 5 folds externos
    save_path="results",
    study_name="mlp_exclusive_optimization"
)
""")

print("\n" + "="*80)
print("‚úÖ RESUMEN")
print("="*80)
print("""
Ahora pod√©s controlar completamente las capas exclusivas desde model_space:

‚Ä¢ Valores fijos: num_exclusive_layers=0, num_exclusive_layers=1, etc.
‚Ä¢ Rangos optimizables: (int, low, high, [step])
‚Ä¢ Combinaciones: Mezclar fijos y optimizables seg√∫n necesites

La b√∫squeda de hiperpar√°metros encontrar√° la mejor configuraci√≥n
de capas exclusivas para tus datos autom√°ticamente!
""")
print("="*80 + "\n")
