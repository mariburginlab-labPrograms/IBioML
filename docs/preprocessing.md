# Preprocesamiento de Datos

IBioML incluye un sistema robusto de preprocesamiento espec√≠ficamente dise√±ado para transformar datos neuronales en formato `.mat` de MATLAB en estructuras optimizadas para machine learning.

## üéØ Visi√≥n General

El preprocesamiento en IBioML realiza las siguientes operaciones:

1. **Carga de datos** desde archivos `.mat`
2. **Incorporaci√≥n de contexto** (informaci√≥n de recompensa)
3. **Creaci√≥n de ventanas temporales** con historia de spikes
4. **Filtrado de calidad** (rendimiento, duraci√≥n de trials)
5. **Limpieza neuronal** (eliminaci√≥n de neuronas con baja actividad)
6. **Generaci√≥n de m√∫ltiples formatos** de datos

## üìä Estructura de Datos de Entrada

### Formato del Archivo .mat

Tu archivo `.mat` debe contener las siguientes variables:

| Variable | Dimensiones | Descripci√≥n |
|----------|-------------|-------------|
| `neuronActivity` | (time_bins, neurons) | Actividad neuronal binaria |
| `position` | (time_bins, 1) | Posici√≥n del sujeto |
| `velocity` | (time_bins, 1) | Velocidad del sujeto |
| `rewCtxt` | (time_bins, 1) | Contexto de recompensa (0/1) |
| `trialFinalBin` | (trials, 1) | √öltimo bin de cada trial |
| `dPrime` | (trials, 1) | Medida de rendimiento por trial |
| `trialDurationInBins` | (trials, 1) | Duraci√≥n de cada trial |

## üîß Configuraci√≥n de Par√°metros

### Par√°metros Principales

```python
from ibioml.preprocessing import preprocess_data

preprocess_data(
    file_path='datasets/mi_experimento.mat',
    file_name_to_save='data/experimento_procesado',
    bins_before=5,      # Ventana temporal hacia atr√°s
    bins_after=5,       # Ventana temporal hacia adelante  
    bins_current=1,     # Bins del momento actual
    threshDPrime=2.5,   # Umbral de rendimiento
    firingMinimo=1000   # Spikes m√≠nimos por neurona
)
```

### Descripci√≥n de Par√°metros

#### `bins_before` y `bins_after`
Define la ventana temporal de contexto:

```python
# Ejemplo con bins_before=3, bins_after=2, bins_current=1
# Para el bin t, se incluyen:
# [t-3, t-2, t-1, t, t+1, t+2] -> ventana de 6 bins total
```

!!! tip "Recomendaciones"
    - **bins_before=5, bins_after=5**: Para capturar contexto temporal amplio
    - **bins_before=3, bins_after=3**: Para an√°lisis m√°s r√°pidos
    - **bins_before=0, bins_after=0**: Solo informaci√≥n instant√°nea

#### `threshDPrime`
Umbral de discriminabilidad para filtrar trials de baja calidad:

- **2.0**: Criterio permisivo (incluye m√°s datos)
- **2.5**: Criterio balanceado (recomendado)
- **3.0**: Criterio estricto (solo trials de alta calidad)

#### `firingMinimo`
N√∫mero m√≠nimo de spikes que debe tener una neurona para ser incluida:

- **500**: Para datasets peque√±os
- **1000**: Valor est√°ndar recomendado
- **2000**: Para an√°lisis que requieren alta actividad

## üìÅ Organizaci√≥n de Archivos de Salida

### Estructura Recomendada

```
data/
‚îú‚îÄ‚îÄ bins200ms/              # Resoluci√≥n temporal
‚îÇ   ‚îú‚îÄ‚îÄ 5_5_1/             # bins_before_after_current
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2_5/           # threshold (2.5 -> "2_5")
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_withCtxt_onlyPosition.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_withCtxt_onlyPosition_flat.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_withCtxt_onlyVelocity.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_withCtxt_onlyVelocity_flat.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_withCtxt_bothTargets.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_withCtxt_bothTargets_flat.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_onlyPosition.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_onlyPosition_flat.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_onlyVelocity.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_onlyVelocity_flat.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experimento_bothTargets.pickle
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ experimento_bothTargets_flat.pickle
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 3_0/           # Otra configuraci√≥n de threshold
‚îÇ   ‚îî‚îÄ‚îÄ 3_3_1/             # Otra configuraci√≥n temporal
‚îî‚îÄ‚îÄ bins100ms/              # Otra resoluci√≥n temporal
```

### Ejemplo de Uso con Organizaci√≥n

```python
preprocess_data(
    file_path='datasets/sujeto_S19.mat',
    file_name_to_save='data/bins200ms/5_5_1/2_5/S19_preprocessed',
    bins_before=5,
    bins_after=5,
    bins_current=1,
    threshDPrime=2.5,
    firingMinimo=1000
)
```

## üì¶ Archivos Generados

### Variantes de Datos

Cada ejecuci√≥n de `preprocess_data` genera **12 archivos** organizados en dos grupos principales:

=== "Con Contexto (`withCtxt`)"
    Incluye informaci√≥n de contexto de recompensa:
    
    - `_withCtxt_onlyPosition.pickle` / `_withCtxt_onlyPosition_flat.pickle`
    - `_withCtxt_onlyVelocity.pickle` / `_withCtxt_onlyVelocity_flat.pickle`
    - `_withCtxt_bothTargets.pickle` / `_withCtxt_bothTargets_flat.pickle`

=== "Sin Contexto"
    Solo informaci√≥n neuronal:
    
    - `_onlyPosition.pickle` / `_onlyPosition_flat.pickle`
    - `_onlyVelocity.pickle` / `_onlyVelocity_flat.pickle`
    - `_bothTargets.pickle` / `_bothTargets_flat.pickle`

### Estructura de Archivos

Cada archivo `.pickle` contiene una tupla:

```python
(X, y, trial_markers)
```

Donde:
- **X**: Datos de entrada (actividad neuronal)
- **y**: Variables objetivo (posici√≥n/velocidad)
- **trial_markers**: Identificadores de trial para cada muestra

## üîç Formatos de Datos

### Datos No Aplanados (para RNNs)

```python
# Estructura: (samples, time_bins, features)
X.shape = (n_samples, bins_before + bins_current + bins_after, n_neurons)
```

![Estructura Tensorial](images/tensor.jpg)

**Uso:** Modelos recurrentes (RNN, LSTM, GRU)

### Datos Aplanados (para MLPs)

```python
# Estructura: (samples, features_flattened)
X_flat.shape = (n_samples, (bins_before + bins_current + bins_after) * n_neurons)
```

![Estructura Aplanada](images/flat.jpg)

**Uso:** Modelos no recurrentes (MLP, SVM, etc.)

## üîß Funciones de Utilidad

### Visualizaci√≥n de Calidad de Datos

```python
from ibioml.preprocessing import plot_trial_duration, plot_low_performance

# Cargar datos para an√°lisis
mat_contents = io.loadmat('datasets/mi_experimento.mat')

# Visualizar duraci√≥n de trials
plot_trial_duration(mat_contents['trialDurationInBins'])

# Visualizar rendimiento por trial
plot_low_performance(mat_contents['dPrime'])
```

### Verificaci√≥n de Archivos Generados

```python
import pickle

# Cargar archivo para verificar
with open('data/experimento_withCtxt_flat.pickle', 'rb') as f:
    X, y, trial_markers = pickle.load(f)

print(f"Forma de X: {X.shape}")
print(f"Forma de y: {y.shape}")
print(f"N√∫mero de trials: {len(np.unique(trial_markers))}")
print(f"Samples por trial (promedio): {len(trial_markers) / len(np.unique(trial_markers)):.1f}")
```

## ‚ö° Optimizaci√≥n de Rendimiento

### Para Datasets Grandes

```python
# Reducir memoria usando par√°metros m√°s restrictivos
preprocess_data(
    file_path='datasets/dataset_grande.mat',
    file_name_to_save='data/dataset_optimizado',
    bins_before=3,          # Ventana m√°s peque√±a
    bins_after=3,
    bins_current=1,
    threshDPrime=3.0,       # Criterio m√°s estricto
    firingMinimo=2000       # Neuronas m√°s activas
)
```

### Procesamiento en Lotes

```python
import os

# Procesar m√∫ltiples archivos
datasets = ['S19.mat', 'S20.mat', 'S21.mat']
base_config = {
    'bins_before': 5,
    'bins_after': 5,
    'bins_current': 1,
    'threshDPrime': 2.5,
    'firingMinimo': 1000
}

for dataset in datasets:
    subject_id = dataset.replace('.mat', '')
    preprocess_data(
        file_path=f'datasets/{dataset}',
        file_name_to_save=f'data/bins200ms/5_5_1/2_5/{subject_id}_preprocessed',
        **base_config
    )
    print(f"‚úÖ Procesado: {subject_id}")
```

## üö® Soluci√≥n de Problemas

### Errores Comunes

!!! warning "KeyError: 'neuronActivity'"
    Verifica que tu archivo `.mat` contenga todas las variables requeridas.

!!! warning "MemoryError durante el preprocesamiento"
    - Reduce `bins_before` y `bins_after`
    - Aumenta `firingMinimo` para filtrar m√°s neuronas
    - Procesa en lotes m√°s peque√±os

!!! warning "Archivos vac√≠os despu√©s del filtrado"
    - Reduce `threshDPrime`
    - Verifica la calidad de tus datos de entrada
    - Ajusta `firingMinimo` a un valor menor

### Verificaci√≥n de Calidad

```python
def verificar_preprocesamiento(archivo_pickle):
    with open(archivo_pickle, 'rb') as f:
        X, y, T = pickle.load(f)
    
    print(f"üìä Resumen de {archivo_pickle}:")
    print(f"   Muestras: {X.shape[0]:,}")
    print(f"   Features: {X.shape[1] if len(X.shape)==2 else X.shape[1]*X.shape[2]:,}")
    print(f"   Targets: {y.shape[1] if len(y.shape)>1 else 1}")
    print(f"   Trials √∫nicos: {len(np.unique(T))}")
    
    # Verificar valores faltantes
    if np.any(np.isnan(X)):
        print("   ‚ö†Ô∏è  Advertencia: Valores NaN en X")
    if np.any(np.isnan(y)):
        print("   ‚ö†Ô∏è  Advertencia: Valores NaN en y")
    
    print("   ‚úÖ Archivo v√°lido")

# Verificar todos los archivos generados
archivos = [
    'data/experimento_withCtxt_flat.pickle',
    'data/experimento_onlyPosition_flat.pickle'
]

for archivo in archivos:
    verificar_preprocesamiento(archivo)
```

## üìà Pr√≥ximos Pasos

Una vez completado el preprocesamiento:

1. **[Configurar experimentos ‚Üí](experiments.md)** Aprende a usar los datos procesados
2. **[API Reference ‚Üí](api/preprocessing.md)** Documentaci√≥n detallada de funciones
3. **[Ejemplos ‚Üí](examples/basic_tutorial.md)** Tutoriales paso a paso
